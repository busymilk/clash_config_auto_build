# -*- coding: utf-8 -*-
import yaml
import glob
import logging
import re
import argparse

# --- é…ç½®æ—¥å¿—è®°å½• ---
# è®¾ç½®æ—¥å¿—çš„æ ¼å¼å’Œçº§åˆ«ï¼Œæ–¹ä¾¿è°ƒè¯•å’Œè¿½è¸ªè„šæœ¬æ‰§è¡Œæƒ…å†µ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()  # è¾“å‡ºåˆ°æ§åˆ¶å°
    ]
)

# --- å¸¸é‡å®šä¹‰ ---
# å®šä¹‰ä¸åŒåœ°åŒºçš„æ­£åˆ™è¡¨è¾¾å¼è¿‡æ»¤å™¨ï¼Œç”¨äºæ ¹æ®èŠ‚ç‚¹åç§°ç­›é€‰ç‰¹å®šåœ°åŒºçš„ä»£ç†
# ä½¿ç”¨ re.compile é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼å¯ä»¥æé«˜åŒ¹é…æ•ˆç‡
FILTER_PATTERNS = {
    'hk': re.compile(
        r'\b(HK|Hong[\s_-]?Kong|HKG|HGC)\b(?!-?(check|fail))|é¦™æ¸¯|æ¸¯|ğŸ‡­ğŸ‡°',
        flags=re.IGNORECASE  # å¿½ç•¥å¤§å°å†™
    ),
    'us': re.compile(
        r'\b(us|usa|america|united[\s-]?states)\b(?!-?(check|fail))|ç¾|ğŸ‡ºğŸ‡¸',
        flags=re.IGNORECASE
    ),
    'jp': re.compile(
        r'\b(jp|japan|tokyo|tyo|osaka|nippon)\b(?!-?(check|fail))|æ—¥æœ¬|æ—¥|ğŸ‡¯ğŸ‡µ',
        flags=re.IGNORECASE
    ),
    'uk': re.compile(
        r'\b(uk|england|britain|united[\s-]?kingdom)\b(?!-?(check|fail))|è‹±å›½|è‹±|ğŸ‡¬ğŸ‡§',
        flags=re.IGNORECASE
    ),
    'sg': re.compile(
        r'\b(sg|singapore|sin)\b(?!-?(check|fail))|æ–°åŠ å¡|æ–°|ğŸ‡¸ğŸ‡¬',
        flags=re.IGNORECASE
    ),
    # åœ¨è¿™é‡Œå¯ä»¥ç»§ç»­æ·»åŠ å…¶ä»–åœ°åŒºçš„-æ­£åˆ™è¡¨è¾¾å¼
}

# å®šä¹‰ä¸å¸Œæœ›åŒ…å«çš„ä»£ç†åç§°å…³é”®è¯ï¼ˆé»‘åå•ï¼‰
BLACKLIST_KEYWORDS = [
    'ç”µæŠ¥', 'æ—¥æœŸ', 'å…è´¹', 'å…³æ³¨'
]

def merge_proxies(proxies_dir, output_file, name_filter=None):
    """
    åˆå¹¶æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ä»£ç†é…ç½®æ–‡ä»¶ã€‚

    :param proxies_dir: å­˜æ”¾ä»£ç†é…ç½®æ–‡ä»¶çš„ç›®å½•è·¯å¾„ (ä¾‹å¦‚: "external_proxies")
    :param output_file: åˆå¹¶åè¾“å‡ºçš„æ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: "merged-proxies.yaml")
    :param name_filter: ä»£ç†åç§°è¿‡æ»¤å™¨, å¯é€‰å€¼ä¸º 'hk', 'us' ç­‰, æˆ– None (ä¸è¿‡æ»¤)
    """
    merged_proxies = []
    # ä½¿ç”¨é›†åˆæ¥å­˜å‚¨å·²è§è¿‡çš„ä»£ç†æ ‡è¯†ç¬¦ï¼Œä»¥å®ç°é«˜æ•ˆå»é‡
    # æ ‡è¯†ç¬¦ç”± (æœåŠ¡å™¨åœ°å€, ç«¯å£, ä»£ç†ç±»å‹) ç»„æˆï¼Œç¡®ä¿èŠ‚ç‚¹çš„å”¯ä¸€æ€§
    seen_identifiers = set()

    # ä½¿ç”¨ glob.glob æŸ¥æ‰¾æ‰€æœ‰è¦å¤„ç†çš„ä»£ç†æ–‡ä»¶
    proxy_files = glob.glob(f"{proxies_dir}/*.*")
    logging.info(f"å‘ç° {len(proxy_files)} ä¸ªä»£ç†æ–‡ä»¶ï¼Œå‡†å¤‡å¼€å§‹å¤„ç†...")

    for file_path in proxy_files:
        try:
            logging.info(f"--- å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path} ---")
            with open(file_path, 'r', encoding="utf-8") as f:
                data = yaml.safe_load(f)

                # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                if not data or 'proxies' not in data:
                    logging.warning(f"æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–ç¼ºå°‘ 'proxies' å­—æ®µ: {file_path}")
                    continue

                file_proxies = data['proxies']
                logging.info(f"ä»æ–‡ä»¶ {file_path} ä¸­å‘ç° {len(file_proxies)} ä¸ªä»£ç†")

                for proxy in file_proxies:
                    # --- æå–ä»£ç†å…³é”®ä¿¡æ¯ ---
                    name = proxy.get('name')
                    server = proxy.get('server')
                    port = proxy.get('port')
                    proxy_type = proxy.get('type')

                    # èŠ‚ç‚¹çš„å”¯ä¸€æ ‡è¯†ç¬¦
                    identifier = (server, proxy_type, port)

                    # --- è¿‡æ»¤é€»è¾‘ ---
                    # 1. æ£€æŸ¥å…³é”®ä¿¡æ¯æ˜¯å¦å®Œæ•´
                    if not all(identifier):
                        logging.warning(f"æ’é™¤ä¿¡æ¯ä¸å®Œæ•´çš„ä»£ç†: {name}")
                        continue

                    # 2. æ£€æŸ¥æ˜¯å¦ä¸ºé‡å¤èŠ‚ç‚¹
                    if identifier in seen_identifiers:
                        logging.info(f"æ’é™¤é‡å¤ä»£ç†: {name} | {server}:{port}")
                        continue
                    
                    # 3. æ’é™¤ç‰¹å®šç±»å‹çš„ä»£ç† (ä¾‹å¦‚: ä¸ç¨³å®šæˆ–è€æ—§çš„ SS ç±»å‹)
                    if proxy_type == 'ss' and proxy.get('cipher', '').lower() == 'ss':
                        logging.info(f"æ’é™¤ä¸å®‰å…¨çš„ SS ä»£ç†: {name}")
                        continue

                    # 4. æ ¹æ®åç§°å…³é”®è¯è¿›è¡Œè¿‡æ»¤
                    if name_filter:
                        # ç™½åå•æ¨¡å¼ï¼šå¦‚æœæä¾›äº†è¿‡æ»¤å™¨ï¼Œåˆ™åªä¿ç•™åç§°åŒ¹é…çš„ä»£ç†
                        if name_filter in FILTER_PATTERNS:
                            if not FILTER_PATTERNS[name_filter].search(name):
                                # logging.info(f"æ’é™¤åç§°ä¸åŒ¹é… '{name_filter}' çš„ä»£ç†: {name}")
                                continue
                        else:
                            logging.error(f"æœªçŸ¥çš„è¿‡æ»¤å™¨: {name_filter}")
                            return # æˆ–è€…æŠ›å‡ºå¼‚å¸¸
                    else:
                        # é»‘åå•æ¨¡å¼ï¼šå¦‚æœæ²¡æœ‰æä¾›è¿‡æ»¤å™¨ï¼Œåˆ™æ’é™¤åŒ…å«é»‘åå•å…³é”®è¯çš„ä»£ç†
                        if any(keyword in name for keyword in BLACKLIST_KEYWORDS):
                            logging.info(f"æ’é™¤å«æœ‰å…³å»ºè¯çš„ä»£ç†: {name}")
                            continue
                    
                    # --- æ·»åŠ ä»£ç† ---
                    # å¦‚æœé€šè¿‡æ‰€æœ‰æ£€æŸ¥ï¼Œåˆ™æ·»åŠ è¯¥ä»£ç†åˆ°åˆ—è¡¨å’Œå»é‡é›†åˆä¸­
                    seen_identifiers.add(identifier)
                    merged_proxies.append(proxy)
                    filter_msg = f"({name_filter}) " if name_filter else ""
                    logging.info(f"æ·»åŠ æ–°ä»£ç† {filter_msg}: {name} | ç±»å‹: {proxy_type} | æœåŠ¡å™¨: {server}:{port}")

        except Exception as e:
            logging.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}", exc_info=True)

    logging.info(f"--- æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆ ---")
    logging.info(f"æ€»å…±åˆå¹¶äº† {len(merged_proxies)} ä¸ªå”¯ä¸€çš„ä»£ç†ã€‚")

    # --- ä¿å­˜åˆå¹¶åçš„ä»£ç†åˆ—è¡¨ ---
    try:
        with open(output_file, 'w', encoding="utf-8") as f:
            # å°†åˆå¹¶åçš„ä»£ç†åˆ—è¡¨ä»¥ YAML æ ¼å¼å†™å…¥æ–‡ä»¶
            # allow_unicode=True ç¡®ä¿ä¸­æ–‡å­—ç¬¦èƒ½æ­£ç¡®æ˜¾ç¤º
            yaml.dump({'proxies': merged_proxies}, f, default_flow_style=False, allow_unicode=True)
        logging.info(f"æˆåŠŸå°†åˆå¹¶åçš„ä»£ç†å†™å…¥åˆ°: {output_file}")
    except IOError as e:
        logging.error(f"å†™å…¥æ–‡ä»¶ {output_file} å¤±è´¥: {e}")


if __name__ == "__main__":
    # --- è§£æå‘½ä»¤è¡Œå‚æ•° ---
    # ä½¿ç”¨ argparse åº“æ¥ä½¿è„šæœ¬å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œæ¥æ”¶å‚æ•°ï¼Œå¢å¼ºçµæ´»æ€§
    parser = argparse.ArgumentParser(
        description="åˆå¹¶ Clash ä»£ç†é…ç½®æ–‡ä»¶ï¼Œæ”¯æŒæŒ‰åœ°åŒºè¿‡æ»¤å’Œå»é‡ã€‚"
    )
    parser.add_argument(
        '--proxies-dir',
        type=str,
        default='external_proxies',
        help='å­˜æ”¾ä»£ç†é…ç½®æ–‡ä»¶çš„ç›®å½•è·¯å¾„'
    )
    parser.add_argument(
        '--output',
        type=str,
        required=True,
        help='åˆå¹¶åè¾“å‡ºçš„æ–‡ä»¶è·¯å¾„ (ä¾‹å¦‚: merged-proxies.yaml)'
    )
    parser.add_argument(
        '--filter',
        type=str,
        choices=FILTER_PATTERNS.keys(), # é™åˆ¶ filter å‚æ•°åªèƒ½æ˜¯é¢„å®šä¹‰çš„key
        help="æ ¹æ®åœ°åŒºå…³é”®è¯è¿‡æ»¤ä»£ç†åç§° (ä¾‹å¦‚: 'hk', 'us')"
    )

    args = parser.parse_args()

    # --- æ‰§è¡Œä¸»å‡½æ•° ---
    logging.info(f"å¼€å§‹æ‰§è¡Œåˆå¹¶ä»»åŠ¡: filter='{args.filter}', output='{args.output}'")
    merge_proxies(args.proxies_dir, args.output, args.filter)
    logging.info("ä»»åŠ¡æ‰§è¡Œå®Œæ¯•ã€‚")